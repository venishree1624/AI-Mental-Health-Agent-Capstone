# ğŸ§  AI Mental Health Support Agent  
### Capstone Project â€“ Google Ã— Kaggle AI Intensive Workshop 2025

An AI-powered **Mental Health Support Agent** designed to provide empathetic conversations, detect emotional distress, perform safety checks, and escalate high-risk situations through a Long-Running Operation (LRO) mechanism.

Track: Agents for Good (Healthcare & Well-being)

---

## ğŸš€ Project Overview

This project demonstrates how **agentic AI systems** can support mental well-being by combining empathy, safety awareness, and structured decision-making.

The agent is capable of:
- Understanding user emotions
- Providing supportive, non-medical responses
- Detecting safety-critical language
- Escalating high-risk cases for human review
- Operating under responsible AI and privacy-first principles

Built as part of the **Google Ã— Kaggle AI Intensive Workshop 2025** under the **â€œAgents for Goodâ€** track.

---

## ğŸ§© Why Agents?

Traditional LLMs often struggle with:
- Maintaining emotional context across interactions
- Handling safety-critical conversations
- Deciding when escalation is required
- Managing structured workflows

Agent-based systems address these challenges by:
- Using tools for reasoning and decision-making
- Maintaining conversational state
- Executing safety logic conditionally
- Supporting long-running operations (LROs)

---

## ğŸ—ï¸ System Architecture

### 1ï¸âƒ£ Conversation (Support) Agent  
Handles empathetic and emotionally aware dialogue.

### 2ï¸âƒ£ Emotion Detection Tool  
Analyzes user input for emotional signals such as:
- sadness
- stress
- anxiety
- risk indicators

### 3ï¸âƒ£ Safety Check Tool  
Evaluates whether the conversation requires escalation.

### 4ï¸âƒ£ LRO Escalation Agent  
Triggers human review during high-risk situations using a simulated Long-Running Operation.

### 5ï¸âƒ£ Final Output Agent  
Returns a structured response summarizing decisions and suggested support actions.

---

## ğŸ› ï¸ Technologies Used

- Python  
- Kaggle Notebooks  
- Google AI Studio (Agents & Workflows concepts)  
- Emotion Detection Tools  
- Safety Evaluation Logic  
- Long-Running Operation (LRO) Simulation  

---

## ğŸ“˜ Kaggle Notebook

â¡ **View the full Kaggle notebook:**  
https://www.kaggle.com/code/venishreet/ai-agent-mental-health-support-system/notebook

---

## ğŸ”® Future Improvements

If extended further, this project could include:
- More granular emotion categories
- Improved safety-risk classification
- Real-time UI or web-based chatbot deployment
- Multilingual support
- Persistent memory across sessions

---

## ğŸ“„ License

This project is licensed under the **Apache License 2.0**.

Â© 2025 Venishree T
