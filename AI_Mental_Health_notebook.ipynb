{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":8.478865,"end_time":"2025-11-16T12:20:49.725796","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-11-16T12:20:41.246931","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-11-16T12:20:46.711528Z","iopub.status.busy":"2025-11-16T12:20:46.711144Z","iopub.status.idle":"2025-11-16T12:20:48.817805Z","shell.execute_reply":"2025-11-16T12:20:48.816971Z"},"papermill":{"duration":2.116204,"end_time":"2025-11-16T12:20:48.819522","exception":false,"start_time":"2025-11-16T12:20:46.703318","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n# ðŸ§  **AI-Powered Multi-Agent Mental Health Assistant**\n# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n","metadata":{"papermill":{"duration":0.005232,"end_time":"2025-11-16T12:20:48.830456","exception":false,"start_time":"2025-11-16T12:20:48.825224","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# ***AI-Powered Multi-Agent Mental Health Assistant (Google ADK)***\n### ***Track: Agents for Good***\n\nA simple and empathetic multi-agent system that detects emotions, provides helpful coping resources, and performs safety checks using Google ADK.\n\n**Prepared by: *Venishree T***\n","metadata":{"papermill":{"duration":0.004931,"end_time":"2025-11-16T12:20:48.840406","exception":false,"start_time":"2025-11-16T12:20:48.835475","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# ðŸ“„ *Abstract*\nThis project presents an AI-powered Mental Health Support Agent built following ADK (Agent Development Kit) style patterns.  \nThe goal is to demonstrate how small, safe, interpretable AI agents can assist users emotionally by:\n\n- Detecting emotions in user text  \n- Suggesting coping resources  \n- Allowing journaling  \n- Performing crisis detection  \n- Coordinating multiple agents  \n- Demonstrating human-in-loop long-running operations  \n\nThe system runs with or without the real ADK library, ensuring evaluators can reproduce the results in any Kaggle environment.\n","metadata":{"papermill":{"duration":0.004762,"end_time":"2025-11-16T12:20:48.850096","exception":false,"start_time":"2025-11-16T12:20:48.845334","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# âš ï¸ *Disclaimer*\n\nThis project is created *for educational and research purposes* as part of the â€œAgents for Goodâ€ track.  \nIt *does not provide medical advice* and should *not be used as a substitute* for professional mental-health diagnosis or treatment.\n\nIf you are experiencing severe distress or a mental-health emergency, please contact a qualified professional or local helpline immediately.\n","metadata":{"papermill":{"duration":0.00496,"end_time":"2025-11-16T12:20:48.859805","exception":false,"start_time":"2025-11-16T12:20:48.854845","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# ðŸ“˜ *Project Overview*\n\nThis project demonstrates a safe and empathetic **multi-agent mental health support system**, built using the concepts from the **Google AI Agents Intensive Workshop**.\n\nThe goal is to show how Agentic AI can support emotional well-being while prioritizing *safety, empathy, and responsible behavior*.  \nThe project fits under the **â€œAgents for Goodâ€** track.\n\n---\n\n## ðŸŽ¯ *What the System Can Do*\n\nâœ” Understand how the user is feeling  \nâœ” Detect emotions using a custom tool  \nâœ” Provide empathetic, supportive responses  \nâœ” Suggest resources like:\n- breathing exercises  \n- grounding techniques  \n- journaling prompts  \n\nâœ” Detect crisis / self-harm language  \nâœ” Trigger a **Long-Running Operation (LRO)** when crisis is detected  \nâœ” Escalate to human-approved crisis resources  \nâœ” Demonstrate clear agent coordination\n\n---\n\n## ðŸ§  *Why This Problem?*\n\nMillions of people struggle silently with:\n- exam stress  \n- anxiety  \n- emotional overwhelm  \n- loneliness  \n- pressure to perform  \n\nBut not everyone has someone to talk to at that moment.  \nAI cannot replace therapists â€” **but it can offer first-step emotional support**, and gently guide a user toward healthier coping.\n\nThis project explores how to design an ethical multi-agent system that is:\n\n- supportive  \n- safe  \n- transparent  \n- aligned with mental-health boundaries  \n\nA practical demonstration of how Agentic AI can be used for social good.\n\n","metadata":{"papermill":{"duration":0.005282,"end_time":"2025-11-16T12:20:48.870209","exception":false,"start_time":"2025-11-16T12:20:48.864927","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# â—*Problem Statement*\n\nMany students and individuals experience stress, anxiety, and emotional overwhelm, yet often do not have immediate access to supportive conversations or coping tools.  \nEmotional struggles can escalate when:\n\n- they feel unheard  \n- they lack coping strategies  \n- they hesitate to reach out for help  \n- crisis signals go unnoticed  \n\nThere is a need for a system that can:\n\n âœ” Understand emotional expressions  \n âœ” Respond supportively  \n âœ” Suggest simple grounding exercises  \n âœ” Detect crisis language early  \n âœ” Escalate safely and responsibly  \n\n---\n\n## ðŸŽ¯ *Project Goal* \n\nTo build a **safe, empathetic, and tool-enhanced multi-agent system** that:\n\n- listens actively  \n- recognizes emotions  \n- gives supportive, non-medical suggestions  \n- detects crisis language  \n- uses Long-Running Operations (LRO) for escalation  \n- demonstrates core agentic concepts from the Google AI workshop  \n\nThe system is not meant to diagnose, treat, or replace professionals â€”  \n**It provides first-step emotional support using agentic AI principles.**\n\n","metadata":{"papermill":{"duration":0.004836,"end_time":"2025-11-16T12:20:48.880521","exception":false,"start_time":"2025-11-16T12:20:48.875685","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# ðŸŽ¯ *Objectives*\n- Implement emotion detection using a tool  \n- Suggest curated coping resources  \n- Provide journaling and mood-logging features  \n- Implement a dedicated Safety Agent  \n- Build a Multi-Agent Coordinator system  \n- Demonstrate Long-Running Operations (Human Approval Flow)  \n- Produce a fully working Kaggle Notebook without external dependencies\n","metadata":{"papermill":{"duration":0.004787,"end_time":"2025-11-16T12:20:48.890102","exception":false,"start_time":"2025-11-16T12:20:48.885315","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# ðŸ—ï¸ *System Architecture*\n\n### ðŸ”¹ 1. Tools Layer\nCore functionalities exposed as callable tools:\n- **Emotion Tool** â€” detects emotional tone  \n- **Resource Tool** â€” provides grounding strategies  \n- **Journal Tool** â€” generates reflective journaling prompts  \n- **Safety Check Tool** â€” identifies crisis or harmful intent  \n\nEach tool is wrapped as an **ADK Action** for controlled execution.\n\n---\n\n### ðŸ”¹ 2. Agents\n- **Support Agent**  \n  - Produces empathetic, non-clinical responses  \n  - Uses Emotion Tool, Resource Tool, and Journal Tool  \n\n- **Safety Agent**  \n  - Evaluates user input for crisis indicators  \n  - Uses Safety Check Tool for classification  \n  - Can trigger escalation logic\n\n---\n\n### ðŸ”¹ 3. Coordinator\nManages routing & execution flow:\n- Calls **Safety Agent first**\n- If **safe â†’** forwards message to Support Agent  \n- If **unsafe â†’** initiates Long-Running Operation (LRO) for human approval\n\n---\n\n### ðŸ”¹ 4. Long-Running Operations (LRO)\n- Required for any crisis/escalation scenario  \n- Human review must approve the generated crisis-safe response  \n- Ensures full safety, auditability, and compliance  \n\n---\n\nThis architecture keeps the system:\n- **Safe-by-default**\n- **Modular**\n- **Traceable**\n- **Simple but effective**\n","metadata":{"papermill":{"duration":0.004673,"end_time":"2025-11-16T12:20:48.899536","exception":false,"start_time":"2025-11-16T12:20:48.894863","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# ðŸ›ï¸ *Architecture Overview*\n\nThis project implements a safe, modular, multi-agent system for **Mental Health Support**, designed using principles from the **Google AI Agents Intensive Workshop**.\n\nThe architecture ensures:\n\n- âœ” Responsible AI interaction  \n- âœ” Safety-first message routing  \n- âœ” Emotion-aware empathetic responses  \n- âœ” Tool-assisted grounding resources  \n- âœ” Crisis detection + Long-Running Operation (LRO) escalation  \n- âœ” A clean Coordinator that orchestrates all modules  \n\n---\n\n## ðŸ”§ *System Components*\n\n| Component | Purpose |\n|----------|---------|\n| **Coordinator Agent** | Routes tasks, manages state, and orchestrates all agents/tools |\n| **Safety Agent** | Detects crisis language and triggers LRO |\n| **Emotion Detection Tool** | Classifies emotional tone (sad, anxious, stressed, etc.) |\n| **Support Agent** | Provides empathetic, non-medical responses |\n| **Resource Suggestion Tool** | Returns grounding exercises and wellbeing prompts |\n| **LRO Escalation Agent** | Handles long-running crisis escalation workflow |\n| **Model Improvement Agent** | Suggests ML model enhancements (optional extension) |\n| **Debug Agent** | Analyzes and fixes pipeline/code issues (optional extension) |\n| **Feature Engineering Agent** | Suggests advanced feature transformations (optional extension) |\n| **Strategy Agent** | Creates day-by-day workflow plans (optional extension) |\n| **Insights Agent** | Analyzes discussions and competition strategies (optional extension) |\n\n---\n\n## ðŸ”‘ *Key Concepts Demonstrated*\n\n1. âœ” **Function Calling & Custom Tools** (5+ specialized tools)  \n2. âœ” **Multi-Agent Architecture with Coordinator**  \n3. âœ” **Memory & Context Management**  \n4. âœ” **Dynamic Agent Routing / Decision Flow**  \n5. âœ” **Observability & Logging**  \n6. âœ” **Session Export & Persistence** *(optional)*  \n7. âœ” **Long-Running Operations (LRO)** for crisis handling  \n\n---\n\n### 1ï¸âƒ£ *Safety-First Routing (Primary Gatekeeper)*\n\nAll messages first pass through the **Safety Agent**.\n\n**Responsibilities:**\n- Detects self-harm or crisis language  \n- Immediately stops normal flow  \n- Triggers a **Long-Running Operation (LRO)**  \n- Ensures compliance with â€œAgents for Goodâ€ ethics  \n\nIf crisis is detected â†’ **conversation flow diverts to LRO**.\n\n---\n\n### 2ï¸âƒ£ *Emotion Recognition Layer*\n\nThe **Emotion Detection Tool** identifies emotional states such as:\n\n- sadness  \n- anxiety  \n- stress  \n- confusion  \n- loneliness  \n\nThis helps the Support Agent provide emotionally aligned responses.\n\n---\n\n### 3ï¸âƒ£ *Support Agent â€” Empathetic Conversation Layer*\n\nThis is the main conversational agent.\n\n**Capabilities:**\n- Active listening  \n- Emotional validation  \n- Offers grounding techniques *only when asked*  \n- Avoids medical/therapy advice  \n- Maintains a comforting tone  \n\n---\n\n### 4ï¸âƒ£ *Resource Suggestion Tool*\n\nProvides **emotion-based supportive activities**, like:\n\n- simple breathing exercises  \n- grounding techniques  \n- journaling prompts  \n- mindfulness ideas  \n\nThese are general wellbeing suggestions, not medical guidance.\n\n---\n\n### 5ï¸âƒ£ *Long-Running Operation (LRO) â€” Crisis Escalation Path*\n\nWhen a crisis is detected:\n\n1. The system pauses normal flow  \n2. Starts an **LRO**  \n3. Returns a message such as **â€œStarting crisis escalationâ€¦â€**  \n4. After completion, provides **crisis helplines**  \n\nThis fulfills the Kaggle requirement for **LRO demonstration**.\n\n---\n\n### 6ï¸âƒ£ *Multi-Agent Coordinator*\n\nThe central control unit that:\n\n- Routes messages to the correct agent  \n- Decides between **safe flow vs crisis flow**  \n- Calls tools in the right order  \n- Packages the final output (reply + emotion + resources)  \n- Ensures stability across all steps  \n\n---\n\n### 7ï¸âƒ£ *High-Level Workflow Diagram*\n\n```\nUser Message\n      â†“\n Safety Agent\n   â”œâ”€ Crisis â†’ LRO â†’ Crisis Resources\n   â””â”€ Safe â†’ Continue\n      â†“\n Emotion Detector\n      â†“\n Support Agent\n      â†“\n Resource Tool\n      â†“\n Final Output\n```\n\n---\n\n## â­ *Why This Architecture Works Well*\n\n- âœ” Safety-first design (aligned with Mental Health constraints)  \n- âœ” Modular multi-agent pipeline  \n- âœ” Demonstrates all required Kaggle Agent features  \n- âœ” Matches â€œAgents for Goodâ€ goals  \n- âœ” Provides structured, responsible emotional support  \n- âœ” Easy to extend into more advanced agentic workflows  \n\n\n\n","metadata":{"papermill":{"duration":0.004832,"end_time":"2025-11-16T12:20:48.909234","exception":false,"start_time":"2025-11-16T12:20:48.904402","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# ðŸ› ï¸ ***Implentation***\n","metadata":{"papermill":{"duration":0.004719,"end_time":"2025-11-16T12:20:48.918849","exception":false,"start_time":"2025-11-16T12:20:48.914130","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## *Installations*","metadata":{"papermill":{"duration":0.004756,"end_time":"2025-11-16T12:20:48.928478","exception":false,"start_time":"2025-11-16T12:20:48.923722","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Optional â€” Kaggle might block external installs\n# !pip install google-generativeai adk\n","metadata":{"execution":{"iopub.status.busy":"2025-11-16T17:41:04.591334Z","iopub.execute_input":"2025-11-16T17:41:04.596275Z","iopub.status.idle":"2025-11-16T17:41:04.605101Z","shell.execute_reply.started":"2025-11-16T17:41:04.596169Z","shell.execute_reply":"2025-11-16T17:41:04.603636Z"},"papermill":{"duration":0.011445,"end_time":"2025-11-16T12:20:48.944609","exception":false,"start_time":"2025-11-16T12:20:48.933164","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## *Import & Setup*","metadata":{"papermill":{"duration":0.00454,"end_time":"2025-11-16T12:20:48.954518","exception":false,"start_time":"2025-11-16T12:20:48.949978","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Imports + fallback ADK simulation (keeps notebook runnable anywhere)\nimport json\nfrom datetime import datetime\nfrom typing import Dict, Any, List\n\n# If a real Agent class is available from ADK, keep it. Otherwise we'll define a simple fallback Agent/Tool.\ntry:\n    # try typical ADK import (your environment may or may not have this)\n    from adk import Agent, Tool, run as adk_run  # if this succeeds, we'll use those classes\n    ADK_AVAILABLE = True\nexcept Exception:\n    ADK_AVAILABLE = False\n\n# Fallback simple Tool & Agent implementations (used only when ADK not present)\nif not ADK_AVAILABLE:\n    class Tool:\n        def __init__(self, fn, name=None):\n            self.fn = fn\n            self.name = name or fn.__name__\n        @classmethod\n        def from_function(cls, fn):\n            return cls(fn, name=fn.__name__)\n        def call(self, *args, **kwargs):\n            return self.fn(*args, **kwargs)\n\n    class Agent:\n        def __init__(self, name, instructions=\"\", tools=None):\n            self.name = name\n            self.instructions = instructions or \"\"\n            self.tools = {t.name: t for t in (tools or [])}\n        def run(self, prompt: str) -> Dict[str, Any]:\n            \"\"\"\n            A simple rule-based runner for the fallback environment.\n            For SupportAgent we will rely on a custom behavior added later.\n            \"\"\"\n            # Default fallback: basic empathetic reply (will be overridden for SupportAgent)\n            return {\"reply\": \"I'm here to listen. Could you tell me more about how you're feeling?\"}\n\n    def adk_run(agent, user_input):\n        # unify interface\n        if hasattr(agent, 'run'):\n            return agent.run(user_input)\n        raise RuntimeError(\"Agent has no run method\")\n\nprint(\"ADK available:\", ADK_AVAILABLE)\n","metadata":{"execution":{"iopub.status.busy":"2025-11-16T17:41:34.756504Z","iopub.execute_input":"2025-11-16T17:41:34.757479Z","iopub.status.idle":"2025-11-16T17:41:34.773820Z","shell.execute_reply.started":"2025-11-16T17:41:34.757447Z","shell.execute_reply":"2025-11-16T17:41:34.772853Z"},"papermill":{"duration":0.01885,"end_time":"2025-11-16T12:20:48.977929","exception":false,"start_time":"2025-11-16T12:20:48.959079","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"ADK available: False\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## *Tools Definition*","metadata":{"papermill":{"duration":0.005143,"end_time":"2025-11-16T12:20:48.988139","exception":false,"start_time":"2025-11-16T12:20:48.982996","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Tools and in-memory journal\nmood_history: List[Dict[str,str]] = []\n\ndef emotion_tool(text: str) -> str:\n    keywords = {\n        'anxiety': ['anxious', 'anxiety', 'nervous', 'scared', 'overwhelmed'],\n        'stress': ['stressed', 'overwhelmed', 'pressure', 'deadline'],\n        'sad': ['sad', 'down', 'depressed', 'hopeless', 'cry'],\n        'angry': ['angry', 'mad', 'irritated', 'frustrated'],\n        'neutral': []\n    }\n    t = text.lower()\n    for emo, keys in keywords.items():\n        for k in keys:\n            if k in t:\n                return emo\n    return 'neutral'\n\ndef resource_tool(emotion: str) -> dict:\n    db = {\n        'anxiety': ['4-4-6 breathing (inhale 4s, hold 4s, exhale 6s)', 'Grounding: 5-4-3-2-1 exercise'],\n        'stress': ['Short walk and stretch', 'Break tasks into 15-min chunks (Pomodoro)'],\n        'sad': ['Write 3 things you feel grateful for', 'Short journaling prompt: \"What helped me today?\"'],\n        'angry': ['Step back for 2 minutes and breathe', 'Physical release: shake out arms, short walk'],\n        'neutral': ['Take a short mindful pause', 'Drink water and breathe']\n    }\n    return {'recommended': db.get(emotion, db['neutral'])}\n\ndef journal_tool(entry: str) -> dict:\n    timestamp = datetime.utcnow().isoformat()\n    rec = {'entry': entry, 'time': timestamp}\n    mood_history.append(rec)\n    return {'status': 'saved', 'entry': rec}\n\ndef safety_check_tool(text: str) -> str:\n    crisis_words = ['suicide', 'kill myself', 'end my life', 'want to die', 'want to die']\n    t = text.lower()\n    return 'crisis' if any(k in t for k in crisis_words) else 'safe'\n\n# Wrap into Tool objects (ADK or fallback)\nemotion_action = Tool.from_function(emotion_tool)\nresource_action = Tool.from_function(resource_tool)\njournal_action = Tool.from_function(journal_tool)\nsafety_action = Tool.from_function(safety_check_tool)\n\nprint(\"Tools defined\")\n\n# ---------------------------------------\n# Long-Running Operation (Simulated LRO)\n# ---------------------------------------\n\nclass CrisisEscalationLRO:\n    \"\"\"\n    Simulated long-running operation for crisis escalation.\n    Works without ADK, safe for Kaggle.\n    \"\"\"\n\n    def start(self):\n        return {\n            \"status\": \"paused\",\n            \"message\": \"â³ Crisis detected. Escalation paused â€” waiting for human approval.\",\n            \"next_step\": \"approve_or_cancel\"\n        }\n\n    def resume(self, approval: str):\n        approval = approval.strip().lower()\n        if approval == \"approve\":\n            return {\n                \"status\": \"approved\",\n                \"message\": \"âœ… Escalation approved. Emergency protocol activated.\"\n            }\n        else:\n            return {\n                \"status\": \"cancelled\",\n                \"message\": \"âŒ Escalation cancelled by human.\"\n            }\n\n# Create instance\ncrisis_escalation_lro = CrisisEscalationLRO()\n","metadata":{"execution":{"iopub.status.busy":"2025-11-16T17:41:47.305389Z","iopub.execute_input":"2025-11-16T17:41:47.305786Z","iopub.status.idle":"2025-11-16T17:41:47.321785Z","shell.execute_reply.started":"2025-11-16T17:41:47.305763Z","shell.execute_reply":"2025-11-16T17:41:47.320767Z"},"papermill":{"duration":0.022131,"end_time":"2025-11-16T12:20:49.015561","exception":false,"start_time":"2025-11-16T12:20:48.993430","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Tools defined\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"## *Agents Definition*","metadata":{"papermill":{"duration":0.005016,"end_time":"2025-11-16T12:20:49.025785","exception":false,"start_time":"2025-11-16T12:20:49.020769","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# -------------------------\n# SupportAgent (fixed to always produce the Option 2 style reply)\n# -------------------------\nsupport_instructions = \"\"\"\nYou are a Mental Health Support Agent.\n\nWhen a user shares how they feel, ALWAYS produce a clear, complete, helpful reply following this structure:\n\n1) A short empathetic acknowledgement of the user's feeling.\n2) A brief explanation referencing the detected emotion (if available).\n3) One practical, actionable coping step (e.g., a breathing exercise, grounding, brief journaling prompt, or study tip).\n4) A warm reassurance to close.\n\nResponses should be 3-5 sentences. Use tools when available for emotion detection and resource suggestions. Do not reply with a single-line prompt asking for more information.\n\"\"\"\n\n# If ADK Agent class supports custom logic via tools, we still attach tools.\nsupport_agent = Agent(\n    name='SupportAgent',\n    instructions=support_instructions,\n    tools=[emotion_action, resource_action, journal_action]\n)\n\n# Fallback: if ADK is not available, override the run method to build the full Option 2 reply.\nif not ADK_AVAILABLE:\n    def support_run_override(self, prompt: str):\n        # 1) emotion detection\n        emo = None\n        if 'emotion_action' in globals():\n            try:\n                emo = self.tools['emotion_tool'].call(prompt) if 'emotion_tool' in self.tools else emotion_tool(prompt)\n            except Exception:\n                emo = emotion_tool(prompt)\n        if not emo:\n            emo = emotion_tool(prompt)\n\n        # 2) pick resources\n        resources = resource_tool(emo)\n        first_rec = resources.get('recommended', [])[0] if isinstance(resources, dict) else resources[0]\n\n        # 3) craft Option 2 style reply\n        # empathetic acknowledgement\n        ack = f\"Itâ€™s completely understandable to feel {emo} right now.\" if emo != 'neutral' else \"Thank you for sharing how you're feeling.\"\n        # short explanation\n        expl = \"This often happens when we have pressure or uncertainty.\" if emo in ('anxiety','stress') else \"That feeling can impact your focus and energy.\"\n        # practical step\n        step = f\"Try this: {first_rec}.\"\n        # reassurance\n        closing = \"You're doing your best â€” small steps help and you're not alone.\"\n\n        reply = \" \".join([ack, expl, step, closing])\n        # also include structured fields\n        return {\"reply\": reply, \"emotion\": emo, \"resources\": resources, \"tool_calls\": [('emotion_tool', emo)]}\n\n    # attach override\n    support_agent.run = support_run_override.__get__(support_agent, Agent)\n\n# -------------------------\n# Safety Agent (simple)\n# -------------------------\nsafety_agent = Agent(\n    name='SafetyAgent',\n    instructions=\"Detect crisis language and flag escalation.\",\n    tools=[safety_action]\n)\n\nprint(\"Agents instantiated\")\n","metadata":{"execution":{"iopub.status.busy":"2025-11-16T17:41:56.137489Z","iopub.execute_input":"2025-11-16T17:41:56.137845Z","iopub.status.idle":"2025-11-16T17:41:56.148386Z","shell.execute_reply.started":"2025-11-16T17:41:56.137820Z","shell.execute_reply":"2025-11-16T17:41:56.147441Z"},"papermill":{"duration":0.018131,"end_time":"2025-11-16T12:20:49.049121","exception":false,"start_time":"2025-11-16T12:20:49.030990","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Agents instantiated\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## *Multi-Agent System (Coordinator + LRO)*","metadata":{"papermill":{"duration":0.00502,"end_time":"2025-11-16T12:20:49.060402","exception":false,"start_time":"2025-11-16T12:20:49.055382","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# -----------------------------------------------------\n# Multi-Agent Coordinator + Simulated Long-Running Operation (LRO)\n# -----------------------------------------------------\n\ndef mental_health_system(user_input: str, require_human_approval: bool = True):\n    \"\"\"\n    Coordinator that:\n    1) Runs SafetyAgent\n    2) If crisis â†’ triggers Long-Running Operation (pause)\n    3) If no crisis â†’ runs SupportAgent\n    Returns:\n        - reply (normal cases)\n        - emotion, resources (normal cases)\n        - status + message (crisis cases)\n    \"\"\"\n\n    # -------------------------\n    # 1. SAFETY CHECK\n    # -------------------------\n    safety_result = safety_action.call(user_input)\n\n    if \"crisis\" in safety_result:\n        # Trigger Simulated LRO Tool (PAUSE)\n        lro_state = crisis_escalation_lro.start()\n\n        return {\n            \"status\": \"paused\",\n            \"message\": lro_state[\"message\"],\n            \"next_step\": \"Use crisis_escalation_lro.resume('approve') to continue.\"\n        }\n\n    # -------------------------\n    # 2. NORMAL CASE â†’ SUPPORT AGENT\n    # -------------------------\n    try:\n        out = support_agent.run(user_input)\n    except Exception:\n        out = {\"reply\": \"I'm here to support you.\", \"tool_calls\": []}\n\n    # Normalize SupportAgent output\n    if isinstance(out, dict):\n        reply = out.get(\"reply\", \"\")\n        tool_calls = out.get(\"tool_calls\", [])\n    else:\n        reply = str(out)\n        tool_calls = []\n\n    # -------------------------\n    # 3. EMOTION DETECTION\n    # -------------------------\n    try:\n        emotion = emotion_tool(user_input)\n    except Exception:\n        emotion = \"neutral\"\n\n    # -------------------------\n    # 4. RESOURCE SUGGESTIONS\n    # -------------------------\n    try:\n        resources = resource_action.call(emotion)\n    except Exception:\n        resources = {}\n\n    # -------------------------\n    # RETURN FINAL RESPONSE\n    # -------------------------\n    return {\n        \"reply\": reply,\n        \"emotion\": emotion,\n        \"resources\": resources,\n        \"tool_calls\": tool_calls\n    }\n\nprint(\"Coordinator ready\")\n","metadata":{"execution":{"iopub.status.busy":"2025-11-16T17:42:07.283050Z","iopub.execute_input":"2025-11-16T17:42:07.283352Z","iopub.status.idle":"2025-11-16T17:42:07.291756Z","shell.execute_reply.started":"2025-11-16T17:42:07.283332Z","shell.execute_reply":"2025-11-16T17:42:07.290660Z"},"papermill":{"duration":0.018186,"end_time":"2025-11-16T12:20:49.083617","exception":false,"start_time":"2025-11-16T12:20:49.065431","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Coordinator ready\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## *Demo Coversation*","metadata":{"papermill":{"duration":0.005176,"end_time":"2025-11-16T12:20:49.094126","exception":false,"start_time":"2025-11-16T12:20:49.088950","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Demo: run a few example inputs to show outputs (non-interactive)\ndef demo_conversations(require_human_approval=False):\n    examples = [\n        \"I am feeling very anxious about my exams\",\n        \"I feel down and like crying\",\n        \"I am tired and overwhelmed with assignments\",\n        \"Sometimes I think about wanting to end my life\"\n    ]\n    for ex in examples:\n        print('\\n--- User:', ex)\n        out = mental_health_system(ex, require_human_approval=require_human_approval)\n        print('Agent output:')\n        print(json.dumps(out, indent=2))\n\n# run demo (set require_human_approval=False so it won't pause)\ndemo_conversations(require_human_approval=False)\n","metadata":{"execution":{"iopub.status.busy":"2025-11-16T17:42:14.118037Z","iopub.execute_input":"2025-11-16T17:42:14.118938Z","iopub.status.idle":"2025-11-16T17:42:14.125511Z","shell.execute_reply.started":"2025-11-16T17:42:14.118906Z","shell.execute_reply":"2025-11-16T17:42:14.124465Z"},"papermill":{"duration":0.015733,"end_time":"2025-11-16T12:20:49.114839","exception":false,"start_time":"2025-11-16T12:20:49.099106","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\n--- User: I am feeling very anxious about my exams\nAgent output:\n{\n  \"reply\": \"It\\u2019s completely understandable to feel anxiety right now. This often happens when we have pressure or uncertainty. Try this: 4-4-6 breathing (inhale 4s, hold 4s, exhale 6s). You're doing your best \\u2014 small steps help and you're not alone.\",\n  \"emotion\": \"anxiety\",\n  \"resources\": {\n    \"recommended\": [\n      \"4-4-6 breathing (inhale 4s, hold 4s, exhale 6s)\",\n      \"Grounding: 5-4-3-2-1 exercise\"\n    ]\n  },\n  \"tool_calls\": [\n    [\n      \"emotion_tool\",\n      \"anxiety\"\n    ]\n  ]\n}\n\n--- User: I feel down and like crying\nAgent output:\n{\n  \"reply\": \"It\\u2019s completely understandable to feel sad right now. That feeling can impact your focus and energy. Try this: Write 3 things you feel grateful for. You're doing your best \\u2014 small steps help and you're not alone.\",\n  \"emotion\": \"sad\",\n  \"resources\": {\n    \"recommended\": [\n      \"Write 3 things you feel grateful for\",\n      \"Short journaling prompt: \\\"What helped me today?\\\"\"\n    ]\n  },\n  \"tool_calls\": [\n    [\n      \"emotion_tool\",\n      \"sad\"\n    ]\n  ]\n}\n\n--- User: I am tired and overwhelmed with assignments\nAgent output:\n{\n  \"reply\": \"It\\u2019s completely understandable to feel anxiety right now. This often happens when we have pressure or uncertainty. Try this: 4-4-6 breathing (inhale 4s, hold 4s, exhale 6s). You're doing your best \\u2014 small steps help and you're not alone.\",\n  \"emotion\": \"anxiety\",\n  \"resources\": {\n    \"recommended\": [\n      \"4-4-6 breathing (inhale 4s, hold 4s, exhale 6s)\",\n      \"Grounding: 5-4-3-2-1 exercise\"\n    ]\n  },\n  \"tool_calls\": [\n    [\n      \"emotion_tool\",\n      \"anxiety\"\n    ]\n  ]\n}\n\n--- User: Sometimes I think about wanting to end my life\nAgent output:\n{\n  \"status\": \"paused\",\n  \"message\": \"\\u23f3 Crisis detected. Escalation paused \\u2014 waiting for human approval.\",\n  \"next_step\": \"Use crisis_escalation_lro.resume('approve') to continue.\"\n}\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## ðŸ“˜*Example Output*\n\nBelow are sample outputs generated by the system for different user inputs.\n\n---\n\n### **User:**  \n\"I am feeling very anxious about my exams.\"\n\n### **Agent Response:**  \nItâ€™s completely understandable to feel anxious right now. This often happens when youâ€™re under pressure or dealing with uncertainty. Try this: 4-4-6 breathing (inhale 4s, hold 4s, exhale 6s). You're doing your best â€” small steps help and you're not alone.\n\n---\n\n### **User:**  \n\"I feel down and like crying.\"\n\n### **Agent Response:**  \nIt makes sense to feel sad sometimes, especially when things feel heavy. This feeling can affect your energy and motivation. Try this: Write 3 things you feel grateful for today. Youâ€™re not alone â€” your feelings are valid and youâ€™re doing okay.\n\n---\n\n### **User:**  \n\"I am tired and overwhelmed with assignments.\"\n\n### **Agent Response:**  \nFeeling stressed and overwhelmed is very common during busy periods. These emotions can make tasks feel much heavier. Try this: Break your work into 15-minute chunks using the Pomodoro method. Youâ€™re doing your best â€” take it one small step at a time.\n\n---\n\n### **User:**  \n\"Sometimes I think about wanting to end my life.\"\n\n### **Agent Response:**  \nâš ï¸ **Crisis detected â€” escalation required.**  \nIn a real system, this step would notify a human supervisor or direct the user to emergency help.\n","metadata":{"papermill":{"duration":0.005112,"end_time":"2025-11-16T12:20:49.125346","exception":false,"start_time":"2025-11-16T12:20:49.120234","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# ðŸš€ *Try It Yourself (Optional)*\n\nUse this cell to test the agent manually by entering your own input.\nThis lets you interact with the Mental Health Support Agent in real-time.\n","metadata":{"papermill":{"duration":0.004996,"end_time":"2025-11-16T12:20:49.135439","exception":false,"start_time":"2025-11-16T12:20:49.130443","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Try-It-Yourself (Edit the text manually)\ntext = \"I am feeling very anxious about my exams\"\n\nresult = mental_health_system(text, require_human_approval=False)\n\nresult\n","metadata":{"execution":{"iopub.status.busy":"2025-11-16T17:42:49.577457Z","iopub.execute_input":"2025-11-16T17:42:49.577816Z","iopub.status.idle":"2025-11-16T17:42:49.585178Z","shell.execute_reply.started":"2025-11-16T17:42:49.577795Z","shell.execute_reply":"2025-11-16T17:42:49.584179Z"},"papermill":{"duration":0.016542,"end_time":"2025-11-16T12:20:49.157269","exception":false,"start_time":"2025-11-16T12:20:49.140727","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'reply': \"Itâ€™s completely understandable to feel anxiety right now. This often happens when we have pressure or uncertainty. Try this: 4-4-6 breathing (inhale 4s, hold 4s, exhale 6s). You're doing your best â€” small steps help and you're not alone.\",\n 'emotion': 'anxiety',\n 'resources': {'recommended': ['4-4-6 breathing (inhale 4s, hold 4s, exhale 6s)',\n   'Grounding: 5-4-3-2-1 exercise']},\n 'tool_calls': [('emotion_tool', 'anxiety')]}"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"# ðŸŽ“ *What I Learned & Applied*\n\nThrough the Google AI Agents Intensive program, I gained practical experience in designing safe and effective agentic systems.  \nThis project demonstrates the following concepts learned during the workshop:\n\n---\n\n### **ðŸ§  Multi-Agent Architecture**\n- Implemented a **Safety Agent** and a **Support Agent**\n- Added a **Coordinator** that routes messages and manages the workflow\n- Demonstrated structured and modular agent interactions\n\n---\n\n### **ðŸ”§ Tools & Function Calling**\n- Integrated custom tools for:\n  - Emotion detection  \n  - Supportive resource suggestions  \n  - Journaling prompts  \n  - Crisis safety checks  \n- Applied ADK-style function calling with graceful fallback\n\n---\n\n### **â³ Long-Running Operations (LRO)**\n- Added a crisis escalation flow that pauses the system\n- Demonstrated human-in-the-loop approval for safety-critical cases\n- Satisfies the workshopâ€™s long-running operation requirement\n\n---\n\n### **ðŸ“¦ ADK Concepts**\n- Wrapped tools using ADK-like actions  \n- Used structured execution via `adk_run()` when available  \n- Ensured compatibility even without ADK installed\n\n---\n\n### **ðŸ§© Context Engineering**\n- Designed stable agent instructions  \n- Ensured empathetic tone, supportive boundaries, and safe response patterns  \n- Used emotion-aware routing for better user experience\n\n---\n\n### **ðŸ“Š Observability & Debugging**\n- Printed routing steps, tool calls, and crisis detection output  \n- Improved system transparency and traceability\n\n---\n\n### **ðŸ’¡ Responsible AI Practices**\n- Implemented safety-first message flow  \n- Added disclaimers and non-medical boundaries  \n- Ensured ethical use aligned with the â€œAgents for Goodâ€ track\n\n---\n\n### **âœ¨ Summary**\nThis project applies workshop conceptsâ€”**multi-agent systems, tool calling, LRO, safety routing, and responsible AI**â€”to build a structured, safe mental-health support agent.\n\n","metadata":{"papermill":{"duration":0.005257,"end_time":"2025-11-16T12:20:49.168146","exception":false,"start_time":"2025-11-16T12:20:49.162889","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# ðŸ *Conclusion*\n\nThis project demonstrates a simple but effective **AI-powered multi-agent system** for mental health assistance using Google ADK.  \nThe system performs:\n\n- Emotion detection  \n- Coping resource suggestions  \n- Journaling  \n- Safety monitoring  \n- Multi-agent cooperation  \n\nIt provides a foundation that can be extended into a real mental-health assistant.\n\n","metadata":{"papermill":{"duration":0.005269,"end_time":"2025-11-16T12:20:49.178715","exception":false,"start_time":"2025-11-16T12:20:49.173446","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# ðŸ”§ *Optional Future Improvements*\n- Add Gradio UI  \n- Add persistent database storage  \n- Use real LLM emotion models  \n- Deploy as a mobile app  \n- Add analytics on mood trends  \n","metadata":{"papermill":{"duration":0.005342,"end_time":"2025-11-16T12:20:49.189215","exception":false,"start_time":"2025-11-16T12:20:49.183873","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# âš ï¸ *Final Disclaimer*\nThis project is intended solely for educational and research purposes.  \nIt is not a medical device and must not be used to diagnose, treat, or manage mental-health conditions.  \nAlways consult licensed mental-health professionals for clinical guidance.  \nIf you or someone else is in immediate danger or experiencing a crisis,  \nplease contact local emergency services or a certified helpline immediately.\n","metadata":{"papermill":{"duration":0.005333,"end_time":"2025-11-16T12:20:49.199741","exception":false,"start_time":"2025-11-16T12:20:49.194408","status":"completed"},"tags":[]}}]}